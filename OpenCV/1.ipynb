{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"Cute Dog.jpg\")  #image read\n",
    "img=cv2.resize(img,(200,200))\n",
    "cv2.imshow(\"Mehul's library\",img) #image show\n",
    "cv2.waitKey(10)               #image frame - wait this much milliseconds\n",
    "# cv2.destroyWindow()             #only 1 window close\n",
    "cv2.destroyAllWindows()         #destroy all windows\n",
    "#when wait key is 0 , then we need to press arrow keys for closing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"Cute Dog.jpg\")  #image read\n",
    "cv2.imshow(\"Mehul's library\",img) #image show\n",
    "cv2.imshow(\"Mehul's library store\",img) #image show\n",
    "cv2.waitKey(3000)               #image frame - wait this much milliseconds\n",
    "cv2.destroyWindow(\"Mehul's library store\")             #only 1 window close\n",
    "# cv2.destroyAllWindows()         #destroy all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"Cute Dog.jpg\")  #image read\n",
    "img=cv2.resize(img,(400,300))\n",
    "img=np.hstack((img,img,img))  #for horizontally adding image\n",
    "img=np.vstack((img,img))  #same for vertically\n",
    "cv2.imshow(\"Mehul's library\",img) #image show\n",
    "cv2.waitKey(10)               #image frame - wait this much milliseconds\n",
    "# cv2.destroyWindow()             #only 1 window close\n",
    "cv2.destroyAllWindows()         #destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slideshow using os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trees and Mountain Photo.jpg',\n",
       " 'Face Photo 2379005.jpeg',\n",
       " 'Peacock Blue Green Brown.jpg',\n",
       " 'J image opencv.png',\n",
       " 'Binary Grid 12x12.png',\n",
       " 'Opening.png',\n",
       " 'Letter J.png',\n",
       " 'Wide Angle Road Photo.jpg',\n",
       " 'Black Horse Green Field.jpg',\n",
       " 'White man portrait.avif',\n",
       " 'Binary Icon 30.png',\n",
       " 'Pexels Pixabay 60597.jpg',\n",
       " 'Closing.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_name=os.listdir(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image\")\n",
    "list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/1.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m img_path \u001b[39m=\u001b[39m path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mname\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(img_path)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mresize(img,(\u001b[39m300\u001b[39;49m,\u001b[39m300\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# img=np.hstack((img,img))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# img=np.vstack((img,img))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# cv2.imshow(\"Mehul\",img)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mehulgupta2409/Documents/Code%20/AI%20ML/AI/OpenCV/1.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mdd\u001b[39m\u001b[39m\"\u001b[39m,img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "for name in list_name:\n",
    "    path = \"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image\"\n",
    "    img_path = path+\"/\"+name\n",
    "    img=cv2.imread(img_path)\n",
    "    img=cv2.resize(img,(300,300))\n",
    "    # img=np.hstack((img,img))\n",
    "    # img=np.vstack((img,img))\n",
    "    # cv2.imshow(\"Mehul\",img)\n",
    "    cv2.imshow(\"dd\",img)\n",
    "    cv2.waitKey(100)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imread Function \n",
    "<h5>1) cv2.read(\"image path\",1)    default(rgb color) </h5>\n",
    "\n",
    "<h5>2) cv2.read(\"image path\",0)    grayscale() </h5>\n",
    "\n",
    "<h5>3) cv2.read(\"image path\",-1)   unchanged </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 5184, 3)\n"
     ]
    }
   ],
   "source": [
    "new_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/Peacock Blue Green Brown.jpg\",1)\n",
    "print(new_img.shape)\n",
    "# cv2.imshow(\"s\",new_img)\n",
    "new_img=cv2.resize(new_img,(600,600))\n",
    "cv2.imshow(\"new window\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the dimension of image got reduced from (x,y,3) to (x,y) ,means There is no third dimension for color channels in grayscale mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 5184)\n"
     ]
    }
   ],
   "source": [
    "new_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Peacock Blue Green Brown.jpg\",0)\n",
    "print(new_img.shape)\n",
    "# cv2.imshow(\"s\",new_img)\n",
    "new_img=cv2.resize(new_img,(600,600))\n",
    "cv2.imshow(\"new window\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 5184, 3)\n"
     ]
    }
   ],
   "source": [
    "new_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Peacock Blue Green Brown.jpg\",-1)\n",
    "print(new_img.shape)\n",
    "# cv2.imshow(\"s\",new_img)\n",
    "new_img=cv2.resize(new_img,(600,600))\n",
    "cv2.imshow(\"new window\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text in Image\n",
    "<h5> cv2.putText function parameters </h5>\n",
    "(img: MatLike, text: str, org: Point, fontFace: int, fontScale: float, color: Scalar, thickness: int = ..., lineType: int = ..., bottomLeftOrigin: bool = ...) -> MatLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Wide Angle Road Photo.jpg\")\n",
    "img_get=cv2.resize(img_get,(500,600))\n",
    "text=\"Champion\"\n",
    "# org is origin of text from top left of image,so we need to mention x and y co-ordinates (in pixels)\n",
    "# fontFace is the font type of text\n",
    "    # font_HERSHEY_SIMPLEX=0\n",
    "    # font_HERSHEY_PLAIN=1\n",
    "    # font_HERSHEY_DUPLEX=2\n",
    "    # font_HERSHEY_COMPLEX=3\n",
    "    # font_HERSHEY_TRIPLEX=4\n",
    "    # font_HERSHEY_COMPLEX_SMALL=5\n",
    "    # font_HERSHEY_SCRIPT_SIMPLEX=6\n",
    "    # font_HERSHEY_SCRIPT_COMPLEX=7\n",
    "# fontScale - size of font(suppose 3, means 3 times,2 means 2 times)\n",
    "\n",
    "# color - BGR(255,0,0)    opposite of RGB(red green blue)\n",
    "    # color=(0,0,255)  means red colour\n",
    "# thickness =3 - is thickness of text\n",
    "# lineType - \n",
    "    # FILLED = -1\n",
    "    # Line_4 = 4\n",
    "    # Line_8 = 8\n",
    "    # Line_AA = 16\n",
    "# bottomLeftOrigin(takes either true or false i.e boolean value) - (optional parameter) - (when it is true then - the image data orign is at the bottom-left corner . Otherwise , it is at the top-left corner)\n",
    "    # kind of mirror image of text\n",
    "text_img=cv2.putText(img_get,text,(50,450),cv2.FONT_HERSHEY_DUPLEX,2,(0,0,255),5,cv2.LINE_8,False)\n",
    "text_img=cv2.putText(img_get,text,(50,150),cv2.FONT_HERSHEY_DUPLEX,2,(255,0,0),5,cv2.LINE_8,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"text\",text_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Line and Rectangle on image - (used in Face detection apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line\n",
    "horse_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Black Horse Green Field.jpg\")\n",
    "horse_img=cv2.resize(horse_img,(1000,500))\n",
    "horse_updateLine_img=cv2.line(horse_img,(450,220),(650,220),(0,0,255),3,cv2.LINE_8)\n",
    "# (img: MatLike, pt1: Point, pt2: Point, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike\n",
    "cv2.imshow(\"new\",horse_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rectangle\n",
    "horse_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Black Horse Green Field.jpg\")\n",
    "horse_img=cv2.resize(horse_img,(600,500))\n",
    "horse_updateLine_img=cv2.putText(horse_img,\"Horse\",(320,180),cv2.FONT_HERSHEY_DUPLEX,1,(180,244,120),3,cv2.LINE_4,False)\n",
    "# (img: MatLike, text: str, org: Point, fontFace: int, fontScale: float, color: Scalar, thickness: int = ..., lineType: int = ..., bottomLeftOrigin: bool = ...) -> MatLike\n",
    "horse_updateLine_img=cv2.rectangle(horse_img,pt1=(320,200),pt2=(360,255),color=(255,255,0),thickness=3,lineType=cv2.LINE_4)\n",
    "# (img: MatLike, pt1: Point, pt2: Point, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike\n",
    "# point 1 and point 2 both are from origin , point2 is opposite of point 1 (i.e on same diagonal)\n",
    "\n",
    "cv2.imshow(\"new\",horse_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Circle and Ellipse on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for circle\n",
    "old_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Trees and Mountain Photo.jpg\")\n",
    "new_img=cv2.resize(old_img,(600,500))\n",
    "new_img=cv2.circle(new_img,(180,150),40,(0,0,200),-1,cv2.LINE_AA)\n",
    "# (img: MatLike, center: Point, radius: int, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike\n",
    "# thickness =2,means outside it will increase its boundary\n",
    "# thickness negative means inside it will increase its boundary , so when we need to blur some image then we use negative thicknes\n",
    "cv2.imshow(\"My window\",new_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ellipse\n",
    "old_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Trees and Mountain Photo.jpg\")\n",
    "old_img=cv2.resize(old_img,(600,500))\n",
    "# (img: MatLike, text: str, org: Point, fontFace: int, fontScale: float, color: Scalar, thickness: int = ..., lineType: int = ..., bottomLeftOrigin: bool = ...) -> MatLike\n",
    "old_img=cv2.putText(old_img,\"Mehul\",(135,150),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2,cv2.LINE_8,False)\n",
    "new_img=cv2.ellipse(\n",
    "    img=old_img,\n",
    "    center=(180,150),\n",
    "    axes=(50,120),\n",
    "    angle=30,\n",
    "    startAngle=0,\n",
    "    endAngle=360,\n",
    "    color=(0,255,0),\n",
    "    thickness=3,\n",
    "    lineType=cv2.LINE_8\n",
    "    )\n",
    "# (img: MatLike, center: Point, radius: int, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike\n",
    "# thickness =2,means outside it will increase its boundary\n",
    "# thickness negative means inside it will increase its boundary (completely at any negative value), so when we need to blur some image then we use negative thicknes\n",
    "cv2.imshow(\"My window\",new_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/4\n",
    "(img: MatLike, center: Point, axes: Size, angle: float, startAngle: float, endAngle: float, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw polygon on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for polygon\n",
    "old_img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Trees and Mountain Photo.jpg\")\n",
    "old_img=cv2.resize(old_img,(600,500))\n",
    "new_img=cv2.polylines(old_img,[np.array([[150,100],[190,80],[230,100],[210,150],[170,150]])],True,(255,255,0),5,cv2.LINE_8)\n",
    "# (img: MatLike, pts: Sequence[MatLike], isClosed: bool, color: Scalar, thickness: int = ..., lineType: int = ..., shift: int = ...) -> MatLike\n",
    "cv2.imshow(\"New window\",new_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations on Image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Peacock Blue Green Brown.jpg\")\n",
    "img_2=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Trees and Mountain Photo.jpg\")\n",
    "# important - we need to make their sizes same\n",
    "img_1=cv2.resize(img_1,(500,500))\n",
    "img_2=cv2.resize(img_2,(500,500))\n",
    "# adding image, according to their intensity\n",
    "img_3=cv2.addWeighted(img_1,0.8,img_2,0.8,1)\n",
    "# (src1: MatLike, alpha: float, src2: MatLike, beta: float, gamma: float, dst: MatLike | None = ..., dtype: int = ...) -> MatLike\n",
    "img_3=cv2.subtract(img_2,img_1)\n",
    "# (src1: MatLike, src2: MatLike, dst: MatLike | None = ..., mask: MatLike | None = ..., dtype: int = ...) -> MatLike\n",
    "cv2.imshow(\"my\",img_3)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Operation on Images using OpenCV (on Binary Images - where only 2 color is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizeing both image\n",
    "img_new_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Grid 12x12.png\")\n",
    "img_new_2=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Icon 30.png\")\n",
    "img_new_1=cv2.resize(img_new_1,(500,500))\n",
    "img_new_2=cv2.resize(img_new_2,(500,500))\n",
    "new=cv2.bitwise_and(img_new_1,img_new_2)\n",
    "combine=np.hstack((img_new_1,img_new_2,new))\n",
    "cv2.imshow(\"file\",combine)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizeing both image\n",
    "img_new_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Grid 12x12.png\")\n",
    "img_new_2=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Icon 30.png\")\n",
    "img_new_1=cv2.resize(img_new_1,(500,500))\n",
    "img_new_2=cv2.resize(img_new_2,(500,500))\n",
    "new=cv2.bitwise_or(img_new_1,img_new_2)\n",
    "combine=np.hstack((img_new_1,img_new_2,new))\n",
    "cv2.imshow(\"file\",combine)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizeing both image\n",
    "img_new_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Grid 12x12.png\")\n",
    "img_new_2=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Icon 30.png\")\n",
    "img_new_1=cv2.resize(img_new_1,(500,500))\n",
    "img_new_2=cv2.resize(img_new_2,(500,500))\n",
    "new_1=cv2.bitwise_not(img_new_1)\n",
    "new_2=cv2.bitwise_not(img_new_2)\n",
    "combine_1=np.hstack((img_new_1,new_1))\n",
    "combine_2=np.hstack((img_new_2,new_2))\n",
    "vert_combine=np.vstack((combine_1,combine_2))\n",
    "cv2.imshow(\"file\",vert_combine)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizeing both image\n",
    "img_new_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Grid 12x12.png\")\n",
    "img_new_2=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Binary Icon 30.png\")\n",
    "img_new_1=cv2.resize(img_new_1,(500,500))\n",
    "img_new_2=cv2.resize(img_new_2,(500,500))\n",
    "new=cv2.bitwise_xor(img_new_1,img_new_2)\n",
    "combine=np.hstack((img_new_1,img_new_2,new))\n",
    "cv2.imshow(\"file\",combine)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new_1=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Black Horse Green Field.jpg\")\n",
    "img_new_1=cv2.resize(img_new_1,(700,500))\n",
    "img_new_1=cv2.bitwise_not(img_new_1)\n",
    "cv2.imshow(\"ef\",img_new_1)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection in an Image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@432.203] global loadsave.cpp:241 findDecoder imread_('/Users/mehulgupta2409/Docnts/Code /AI ML/Pythonume/AI/OpenCV/Image/Face Photo 2379005.jpeg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"/Users/mehulgupta2409/Docnts/Code /AI ML/Pythonume/AI/OpenCV/Image/Face Photo 2379005.jpeg\")\n",
    "# img=cv2.resize(img,(600,400))\n",
    "new_img=cv2.Canny(img,102,100,apertureSize=5,L2gradient=True)\n",
    "# print(new_img.shape)\n",
    "# print(img.shape)\n",
    "cv2.imshow(\"NEmW\",img)\n",
    "# cv2.imshow(\"NEW\",new_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Scaling,Rotating using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotating the image\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Trees and Mountain Photo.jpg\")\n",
    "img=cv2.resize(img,(600,500))\n",
    "mass=cv2.getRotationMatrix2D((300,250),90,1)\n",
    "# now we need to rotate img by (multiplying) this 2 image\n",
    "new_img=cv2.warpAffine(img,mass,(600,500))\n",
    "# new_img\n",
    "cv2.imshow(\"nee\",new_img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Blurring using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur\n",
    "# Median Blur\n",
    "# Bilateral Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Wide Angle Road Photo.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# new_img=cv2.GaussianBlur(img,(7,7),0)\n",
    "# new_img=cv2.medianBlur(img,3)\n",
    "new_img=cv2.bilateralFilter(img,9,100,100)\n",
    "h=np.hstack((img,new_img))\n",
    "cv2.imshow(\"a\",h)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imwrite method using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Peacock Blue Green Brown.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.resize(img,(400,300))\n",
    "h=np.hstack((img,img))\n",
    "v=np.vstack((h,h))\n",
    "# v.shape\n",
    "cv2.imshow(\"d\",v)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"/Users/mehulgupta2409/Downloads/mehul.png\",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Border using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving border to image\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/Python/AI/OpenCV/Image/Face Photo 2379005.jpeg\")\n",
    "img=cv2.resize(img,(500,400))\n",
    "img_1=cv2.copyMakeBorder(img,20,20,20,20,cv2.BORDER_CONSTANT,None,2)\n",
    "img_1=cv2.resize(img_1,(500,400))\n",
    "img_2=cv2.copyMakeBorder(img,20,20,20,20,cv2.BORDER_DEFAULT,None,2)\n",
    "img_2=cv2.resize(img_2,(500,400))\n",
    "img_3=cv2.copyMakeBorder(img,20,20,20,20,cv2.BORDER_REFLECT_101,None,2)\n",
    "img_3=cv2.resize(img_3,(500,400))\n",
    "# img_2=\n",
    "# img_3=\n",
    "# img_4=\n",
    "h=np.hstack((img,img_1,img_2,img_3))\n",
    "cv2.imshow(\"d\",h)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(\"/Users/mehulgupta2409/Downloads/Videos/Niagara Falls UHD 30fps.mp4\")\n",
    "while True:\n",
    "    r,frame=cap.read()  #frame is imgaes per second , and r is boolean value ,if its true then video is still left and should continue to play but if it's false then video is ended so break statement is used\n",
    "    if r==False:\n",
    "        break\n",
    "    frame=cv2.resize(frame,(600,500))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(25) & 0xfff==ord(\"p\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture video from camera using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self camera\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==False:\n",
    "        break\n",
    "    frame=cv2.resize(frame,(600,500))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(25) & 0xfff==ord(\"p\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow and Fast Motion of Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(\"/Users/mehulgupta2409/Downloads/Videos/mountain.mp4\")\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==False:\n",
    "        break\n",
    "    frame=cv2.resize(frame,(600,500))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(1) & 0xfff==ord(\"p\"): # varying the number inside waitkey can give us slow and fast video motion\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Operations using OpenCV - Part 1\n",
    "### 1)Erosion\n",
    "### 2)Delation\n",
    "### 3)Opening\n",
    "### 4)Closing\n",
    "### 5)Morphological gradient\n",
    "### 6)Black hat\n",
    "### 7)Top hat(also called White hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erosion - It erodes away the boundaries of foreground object (always try to keep foreground in white)\n",
    "#           The kernel slides through the image(as in 2d convolution)\n",
    "#           A pixel in the original image(either 1 or 0) will be considered 1 only when all the pixel under kernel is 1, otherwise 0\n",
    "#           Erosion removes the white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilation - A pixel value is 1 , only when at least 1 of kernel pixel is 1, otherwise 0\n",
    "#           So it increases the white region in the image or size of foreground object increases\n",
    "#           Normally in cases like noise removal,erosion is followed by dilation . Because erosion removes white noise , but also shrinks our object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening - Just another name of erosion after dilation\n",
    "#           It is useful for noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing - Closing is reverse of Opening,Dilation followed by Erosion\n",
    "#           It is useful in closing small holes inside the foreground objects , or small black points on the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological Gradient - It is the difference between dilation and erosion of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Hat(White Hat) - It is the difference between input image and Opening of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black Hat - It is the difference between closing of the input image and the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/Binary Icon 30.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# we need kernel matrix - mass(m)\n",
    "m=np.ones((3,3),np.int64)\n",
    "# print(m)\n",
    "\n",
    "# Erosion\n",
    "# erode=cv2.erode(img,m,iterations=1)\n",
    "# erode=cv2.resize(erode,(500,500))\n",
    "# h=np.hstack((img,erode))\n",
    "\n",
    "# Dilation\n",
    "di=cv2.dilate(img,m,iterations=1)\n",
    "di=cv2.resize(di,(500,500))\n",
    "h=np.hstack((img,di))\n",
    "cv2.imshow(\"erode\",h)\n",
    "# cv2.imshow(\"m\",img)\n",
    "cv2.waitKey(20)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/Screenshot 2024-09-01 at 2.38.56 PM.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# noisy image with background\n",
    "kernel=np.ones((3,3),np.int8)\n",
    "op = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel=kernel,iterations=6)   #op is opening morphological operation\n",
    "op=cv2.resize(op,(500,500))\n",
    "h=np.hstack((img,op))\n",
    "cv2.imshow(\"name\",h)\n",
    "cv2.waitKey(25)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/Closing.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# noisy image with background\n",
    "kernel=np.ones((3,3),np.int8)\n",
    "cl = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel=kernel,iterations=8)   #op is opening morphological operation\n",
    "cl=cv2.resize(cl,(500,500))\n",
    "h=np.hstack((img,cl))\n",
    "cv2.imshow(\"name\",h)\n",
    "cv2.waitKey(25)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological Gradient\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/J image opencv.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# noisy image with background\n",
    "kernel=np.ones((3,3),np.int8)\n",
    "gr = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel=kernel,iterations=8)   #op is opening morphological operation\n",
    "gr=cv2.resize(gr,(500,500))\n",
    "h=np.hstack((img,gr))\n",
    "cv2.imshow(\"name\",h)\n",
    "cv2.waitKey(25)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top(White) Hat - Hardness part is removed\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/J image opencv.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# noisy image with background\n",
    "kernel=np.ones((3,3),np.int8)\n",
    "tophat = cv2.morphologyEx(img,cv2.MORPH_TOPHAT,kernel=kernel,iterations=16)   #op is opening morphological operation\n",
    "tophat=cv2.resize(tophat,(500,500))\n",
    "h=np.hstack((img,tophat))\n",
    "cv2.imshow(\"name\",h)\n",
    "cv2.waitKey(25)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black Hat - Hardness part is removed\n",
    "img=cv2.imread(\"/Users/mehulgupta2409/Documents/Code /AI ML/AI/OpenCV/Image/J image opencv.png\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "# noisy image with background\n",
    "kernel=np.ones((30,30),np.int8)\n",
    "blackhat = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,kernel=kernel,iterations=1)   #op is opening morphological operation\n",
    "blackhat=cv2.resize(blackhat,(500,500))\n",
    "h=np.hstack((img,blackhat))\n",
    "cv2.imshow(\"name\",h)\n",
    "cv2.waitKey(25)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
